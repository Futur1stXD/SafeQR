{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167517</th>\n",
       "      <td>ennislovedjack.blogspot.com/</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582626</th>\n",
       "      <td>belabrazilspa.com/ddjjsua/hl.php</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>cemetery.canadagenweb.org/BC/BCR0715/</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463735</th>\n",
       "      <td>http://sourceforge.net/directory/communication...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468929</th>\n",
       "      <td>space.about.com/od/spaceexplorationhistory/p/v...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  type\n",
       "167517                       ennislovedjack.blogspot.com/  good\n",
       "582626                   belabrazilspa.com/ddjjsua/hl.php  good\n",
       "159568              cemetery.canadagenweb.org/BC/BCR0715/  good\n",
       "463735  http://sourceforge.net/directory/communication...  good\n",
       "468929  space.about.com/od/spaceexplorationhistory/p/v...  good"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/malicious.csv')\n",
    "\n",
    "benign_subset = df[df['type'] == 'benign'].sample(frac=0.25)\n",
    "malicious_subset = df[(df['type'] == 'malware') | (df['type'] == 'defacement')]\n",
    "benign_subset['type'] = benign_subset['type'].replace({'benign': 'good'})\n",
    "\n",
    "df = pd.concat([benign_subset, malicious_subset])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+')\n",
    "\n",
    "df['text_tokenized'] = df.url.map(lambda t: tokenizer.tokenize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "df['text_stemmed'] = df['text_tokenized'].map(lambda l: [stemmer.stem(word = word) for word in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167517</th>\n",
       "      <td>ennislovedjack.blogspot.com/</td>\n",
       "      <td>good</td>\n",
       "      <td>[ennislovedjack, blogspot, com]</td>\n",
       "      <td>[ennislovedjack, blogspot, com]</td>\n",
       "      <td>ennislovedjack blogspot com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582626</th>\n",
       "      <td>belabrazilspa.com/ddjjsua/hl.php</td>\n",
       "      <td>good</td>\n",
       "      <td>[belabrazilspa, com, ddjjsua, hl, php]</td>\n",
       "      <td>[belabrazilspa, com, ddjjsua, hl, php]</td>\n",
       "      <td>belabrazilspa com ddjjsua hl php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>cemetery.canadagenweb.org/BC/BCR0715/</td>\n",
       "      <td>good</td>\n",
       "      <td>[cemetery, canadagenweb, org, BC, BCR]</td>\n",
       "      <td>[cemeteri, canadagenweb, org, bc, bcr]</td>\n",
       "      <td>cemeteri canadagenweb org bc bcr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463735</th>\n",
       "      <td>http://sourceforge.net/directory/communication...</td>\n",
       "      <td>good</td>\n",
       "      <td>[http, sourceforge, net, directory, communicat...</td>\n",
       "      <td>[http, sourceforg, net, directori, communic, a...</td>\n",
       "      <td>http sourceforg net directori communic add fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468929</th>\n",
       "      <td>space.about.com/od/spaceexplorationhistory/p/v...</td>\n",
       "      <td>good</td>\n",
       "      <td>[space, about, com, od, spaceexplorationhistor...</td>\n",
       "      <td>[space, about, com, od, spaceexplorationhistor...</td>\n",
       "      <td>space about com od spaceexplorationhistori p v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  type  \\\n",
       "167517                       ennislovedjack.blogspot.com/  good   \n",
       "582626                   belabrazilspa.com/ddjjsua/hl.php  good   \n",
       "159568              cemetery.canadagenweb.org/BC/BCR0715/  good   \n",
       "463735  http://sourceforge.net/directory/communication...  good   \n",
       "468929  space.about.com/od/spaceexplorationhistory/p/v...  good   \n",
       "\n",
       "                                           text_tokenized  \\\n",
       "167517                    [ennislovedjack, blogspot, com]   \n",
       "582626             [belabrazilspa, com, ddjjsua, hl, php]   \n",
       "159568             [cemetery, canadagenweb, org, BC, BCR]   \n",
       "463735  [http, sourceforge, net, directory, communicat...   \n",
       "468929  [space, about, com, od, spaceexplorationhistor...   \n",
       "\n",
       "                                             text_stemmed  \\\n",
       "167517                    [ennislovedjack, blogspot, com]   \n",
       "582626             [belabrazilspa, com, ddjjsua, hl, php]   \n",
       "159568             [cemeteri, canadagenweb, org, bc, bcr]   \n",
       "463735  [http, sourceforg, net, directori, communic, a...   \n",
       "468929  [space, about, com, od, spaceexplorationhistor...   \n",
       "\n",
       "                                                text_sent  \n",
       "167517                        ennislovedjack blogspot com  \n",
       "582626                   belabrazilspa com ddjjsua hl php  \n",
       "159568                   cemeteri canadagenweb org bc bcr  \n",
       "463735  http sourceforg net directori communic add fac...  \n",
       "468929  space about com od spaceexplorationhistori p v...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_sent'] = df['text_stemmed'].map(lambda l: ' '.join(l))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "feature = cv.fit_transform(df.text_sent)\n",
    "\n",
    "feature[:5].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(feature, df.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9941187437501059"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(trainX, trainY)\n",
    "\n",
    "lr.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668988661209132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(trainX, trainY)\n",
    "\n",
    "mnb.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9945594142472162"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_ls = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize, stop_words = 'english'), LogisticRegression())\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(df.url, df.type)\n",
    "\n",
    "pipeline_ls.fit(trainX, trainY)\n",
    "\n",
    "pipeline_ls.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline_ls, open('../models/malware-defacement.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good' 'good' 'malware' 'good']\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('../models/malware-defacement.pkl', 'rb'))\n",
    "\n",
    "test = ['kaspi.kz', 'avtobys.kz', 'rutracker.ru/mal.exe', 'youtube.com']\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "tokenized = [tokenizer.tokenize(t) for t in test]\n",
    "stemmed = [[stemmer.stem(word=word) for word in l] for l in tokenized]\n",
    "sent = [' '.join(l) for l in stemmed] \n",
    "\n",
    "print(loaded_model.predict(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
